\chapter{Sharing research products}
\doublespace

It is unknown how many experimental campaigns have been redundant due to lack of
openness in the research process. While one may argue this is good for the
repeatability of research, it can lead to ``reinvention of the wheel,'' whose
inefficiency is especially important in this age of diminishing research
funding. It was therefore a secondary goal of all the work performed herein was
to share the products in an open and useful manner.

One important objective is to distribute research products (code, data, CAD
files, etc.) openly, such that they are as useful and reproducible as possible.
It is also important that the code is set up to grow and evolve via
contributions from the community---one of the most significant advantages of the
open-source development model. One example occurred during this research, where
an OpenFOAM case, hosted openly on GitHub, received contributions from a random
user, since he or she was going to create something similar, but now didn't have
to.

Unfortunately, a lot of research code is merely described in publications, but
never released for adoption and improvement by the community. For example,
Shamsoddin and Porte-Agel have written a cross-flow turbine actuator line model
for LES, but have not made their code available or described results regarding
performance prediction \cite{Shamsoddin2014}. Even CACTUS, despite being
open-source, is simply distributed as a static archive for download, so there is
no clear procedure for users to contribute to the code.

To help correct this issue, the results of this research will be open-source and
hosted on GitHub.com to facilitate the inclusion of improvements by other
developers through their fork/pull mechanism. We have already implemented a
sharing strategy for experimental results using GitHub to host code and
processed data, and figshare.com for raw data, CAD files, and snapshots of code
or simulation settings used in specific publications
\cite{Bachant2014-RVAT-baseline, Bachant2014-RVAT-CAD,
Bachant2014-OF-AS-case-files, Bachant2015-RVAT-Re-dep-data}. We will continue to
share results in this way to ensure maximum impact from reuse, remixing, etc.
Furthermore, the library developed here will be openly available through all
stages of development (in fact, it is already), which will hopefully prevent
other developers from unknowingly working on similar projects, and collaborating
instead.


\todo[inline]{Clean up open turbine data sources.}

%%% Below is some rough information from some research I did searching for open data

I sent a request for the MEXICO data. You need to essentially fill out an NDA
since the turbine uses DTU airfoils, which are proprietary. I think you may have
an angle on this proposal that there is almost no truly open data out there by
the definitions of \url{http://opendatahandbook.org/guide/en/what-is-open-data/}

To get data from the NREL Phase VI Ames test, according to a post I saw on the
NREL forum, you need to write a specific request to an individual, and he may or
may not comply based on how inconvenient this is! See
\url{https://wind.nrel.gov/forum/wind/viewtopic.php?f=13&t=975}. Maybe necessary
when storage/bandwidth was limited, but probably not any more. I'd like to see
how big the data really is.

The UMN 2.5 MW wind turbine data is available to consortium members---this is
still not open. See
\url{http://www.eolos.umn.edu/facilities/eolos-wind-research-station}.

Data from the Lignarolo experiment is supposedly available, but requires access
to the article, which is behind a pay wall \cite{Lignarolo2014}.

At METS 2014, someone mentioned that they were perfectly happy to share their
data, but it was so plentiful that they didn't know what to do with it.

I believe that working in a closed or semi-closed fashion is exclusionary and
helps maintain research ``inequality,'' i.e., smaller or less-funded research
groups have lower potential to contribute since they do not have access to code
or data. This may not be attributable to a truly malicious motive to maintain
research ``dynasties,'' but it does have that effect. This is especially
apparent with code, where a group may need to re-implement a whole host of
algorithms in order to produce an incremental improvement that is quite easy for
an established group.

