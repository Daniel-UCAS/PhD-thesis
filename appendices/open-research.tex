\chapter{Sharing research products}
\doublespace

It is unknown how many experimental campaigns have been redundant due to lack of
openness in the research process. While one may argue this is good for the
repeatability of research, it can lead to ``reinvention of the wheel,'' whose
inefficiency is especially important in this age of diminishing research
funding. It was therefore a secondary goal of all the work performed herein was
to share the products in an open and useful manner.

One important objective is to distribute research products (code, data, CAD
files, etc.) openly, such that they are as useful and reproducible as possible.
It is also important that the code is set up to grow and evolve via
contributions from the community---one of the most significant advantages of the
open-source development model. One example occurred during this research, where
an OpenFOAM case, hosted openly on GitHub, received contributions from a random
user, since he or she was going to create something similar, but now didn't have
to.

Unfortunately, a lot of research code is merely described in publications, but
never released for adoption and improvement by the community. For example,
Shamsoddin and Porte-Agel have written a cross-flow turbine actuator line model
for LES, but have not made their code available or described results regarding
performance prediction \cite{Shamsoddin2014}. Even CACTUS, despite being
open-source, is simply distributed as a static archive for download, so there is
no clear procedure for users to contribute to the code.

To help correct this issue, the results of this research will be open-source and
hosted on GitHub.com to facilitate the inclusion of improvements by other
developers through their fork/pull mechanism. We have already implemented a
sharing strategy for experimental results using GitHub to host code and
processed data, and figshare.com for raw data, CAD files, and snapshots of code
or simulation settings used in specific publications
\cite{Bachant2014-RVAT-baseline, Bachant2014-RVAT-CAD,
Bachant2014-OF-AS-case-files, Bachant2015-RVAT-Re-dep-data}. We will continue to
share results in this way to ensure maximum impact from reuse, remixing, etc.
Furthermore, the library developed here will be openly available through all
stages of development (in fact, it is already), which will hopefully prevent
other developers from unknowingly working on similar projects, and collaborating
instead.


\todo[inline]{Clean up open turbine data sources.}

%%% Below is some rough information from some research I did searching for open data

I sent a request for the MEXICO data. You need to essentially fill out an NDA
since the turbine uses DTU airfoils, which are proprietary. I think you may have
an angle on this proposal that there is almost no truly open data out there by
the definitions of \url{http://opendatahandbook.org/guide/en/what-is-open-data/}

To get data from the NREL Phase VI Ames test, according to a post I saw on the
NREL forum, you need to write a specific request to an individual, and he may or
may not comply based on how inconvenient this is! See
\url{https://wind.nrel.gov/forum/wind/viewtopic.php?f=13&t=975}. Maybe necessary
when storage/bandwidth was limited, but probably not any more. I'd like to see
how big the data really is.

The UMN 2.5 MW wind turbine data is available to consortium members---this is
still not open. See
\url{http://www.eolos.umn.edu/facilities/eolos-wind-research-station}.

Data from the Lignarolo experiment is supposedly available, but requires access
to the article, which is behind a pay wall \cite{Lignarolo2014}.

At METS 2014, someone mentioned that they were perfectly happy to share their
data, but it was so plentiful that they didn't know what to do with it.

I believe that working in a closed or semi-closed fashion is exclusionary and
helps maintain research ``inequality,'' i.e., smaller or less-funded research
groups have lower potential to contribute since they do not have access to code
or data. This may not be attributable to a truly malicious motive to maintain
research ``dynasties,'' but it does have that effect. This is especially
apparent with code, where a group may need to re-implement a whole host of
algorithms in order to produce an incremental improvement that is quite easy for
an established group.

Chapter~\ref{chap:CFD} and Chapter~\ref{chap:ALM} would probably not have been
possible without the free availability of OpenFOAM thanks to the OpenFOAM
foundation.


%%% Stuff from data management plan in a proposal

Data management will be based on the guiding principles of reproducibility,
usability, and maintainability. Reproducibility means the origin of all data can
be identified, and any derived data can be regenerated from the raw data, which
should also be available. In practice this means providing processing software
used to generate the derived datasets. It also means archiving specific versions
of software used to generate figures for publications, and citing these therein
via digital object identifier (DOI). Usability means that if possible, data
should be provided in non-proprietary, standard formats, e.g., comma-separated
value (CSV) text files, and code used for visualization should also be shared.
Finally, the research products should be maintainable, i.e., there should be a
mechanism for incorporating new analyses, corrections to derived datasets, etc.
In practice this will be achieved by structuring each experiment around a
version control repository, which will include code used to automate data
collection (if applicable), processing, and visualization. This way, updates to
derived datasets are linked to changes in software. Furthermore, the version
control repository will be of a “distributed” nature, which will open up avenues
for collaboration and continued enhancement of the research products beyond the
initial release.

In accordance with the principles of open data
(http://opendatahandbook.org/guide/en/what-is-open-data/), all data from the
experiment will be available and accessible, able to be reused and redistributed
freely under the terms of a Creative Commons Attribution license. Code will be
made available under the open-source MIT software license.


\section{Content and Formats}

The digital data, including metadata, will be stored in easily accessible (human
and machine readable) formats, using a standard plain text format, e.g., CSV,
JSON, YAML, wherever possible. Raw binary data will be saved in or converted to
open formats such as HDF5 if possible. Software will be kept in a version
control repository to document changes and the rationale behind them, which will
also link software modifications to changes in derived datasets. Software
dependencies will be noted, e.g., using text files to specify virtual
environments, such that the analysis is reproducible. Free and open-source
software will be used preferred to help maximize usability. File and directory
structure/naming will be documented inside the version control repository. The
processing code algorithms will also help identify data files and their usage.


\section{Sharing and Preservation}

Raw data and metadata will be both stored locally at UNH and uploaded to the
online data repository figshare, which will provide persistent storage for
approximately 10 years
(https://figshare.zendesk.com/hc/en-us/articles/201953923-How-persistent-is-my-research-). CAD files of the turbine model will also be uploaded to figshare and be made openly available after completion of the design. Data recorded on paper, e.g. lab notebooks, will be kept in appropriate storage in the P.I.'s lab.

Each experiment or project will have its own Git version control repository,
which will contain code developed to process and visualize the data, and will be
hosted via GitHub or similar service. This online repository will serve as the
``home page'' for the project, and will provide the mechanism for both
downloading, reporting issues with, and contributing to the project. Links for
downloading other related research products that are not conducive to Git
repositories, e.g., CAD files, will be provided in the README file, the content
from which is also displayed on the repository's home page. Processed or derived
data that take considerable time to generate will also be stored in the Git
repository. If digital lab notebooks are used, these will also be included. The
processing software will contain mechanisms or instructions for downloading raw
data as needed to regenerate the derived datasets.

After appropriate quality assurance and quality control, and typically
concurrent with the submission of a manuscript to a journal, the version control
repository will be made publicly available, and official releases will be
archived via figshare or similar sites, which provide a DOI for a persistent
citation in publications. Examples of this practice can be found in the datasets
published by Bachant and Wosnik 2014c, 2015b and Bachant et al. 2015b. This
helps with reproducibility since the data and code used to generate figures is
cited in the containing publication.

Archived versions of and links to the experimental repository will then be
posted on data indexing and aggregation sites, such as OpenEI
(http://openei.org). The releases will also be publicized via social media and
organizational websites and newsletters.
